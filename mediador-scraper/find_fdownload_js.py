#!/usr/bin/env python3
"""
Descobrir onde a fun√ß√£o fDownload() est√° definida
Analisando scripts JS carregados pela p√°gina
"""

import requests
from bs4 import BeautifulSoup
import re

print("üîç PROCURANDO DEFINI√á√ÉO DA FUN√á√ÉO fDownload()")
print("="*60)

# Buscar p√°gina principal
url = "https://www3.mte.gov.br/sistemas/mediador/ConsultarInstColetivo"
print(f"\nüì• Baixando: {url}")

session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
})

try:
    # Ignorar SSL errors
    response = session.get(url, verify=False, timeout=30)
    print(f"‚úÖ Status: {response.status_code}")

    soup = BeautifulSoup(response.text, "html.parser")

    # Procurar todos os <script src="...">
    scripts = soup.find_all("script", src=True)
    print(f"\nüìã {len(scripts)} scripts externos encontrados:")

    js_urls = []
    for script in scripts:
        src = script.get("src")
        # Construir URL completa
        if src.startswith("/"):
            full_url = f"https://www3.mte.gov.br{src}"
        elif src.startswith("http"):
            full_url = src
        else:
            full_url = f"https://www3.mte.gov.br/sistemas/mediador/{src}"

        print(f"  - {src}")
        js_urls.append((src, full_url))

    # Baixar cada script e procurar fDownload
    print(f"\nüîé Procurando fDownload nos scripts...")

    for name, url in js_urls:
        try:
            js_response = session.get(url, verify=False, timeout=10)
            if js_response.status_code == 200:
                content = js_response.text

                # Procurar fun√ß√£o fDownload
                if "fDownload" in content:
                    print(f"\n‚úÖ ENCONTRADO em: {name}")
                    print(f"   URL: {url}")

                    # Extrair a defini√ß√£o da fun√ß√£o
                    match = re.search(r"function\s+fDownload\s*\([^)]*\)\s*\{[^}]*\}", content, re.DOTALL)
                    if match:
                        func_code = match.group(0)
                        print(f"\nüìú Defini√ß√£o da fun√ß√£o:")
                        print("-" * 60)
                        print(func_code[:500])  # Primeiros 500 chars
                        if len(func_code) > 500:
                            print("...")
                        print("-" * 60)

                    # Salvar script completo para an√°lise
                    with open("fDownload_script.js", "w", encoding="utf-8") as f:
                        f.write(content)
                    print(f"\nüíæ Script completo salvo em: fDownload_script.js")
                    break
        except Exception as e:
            print(f"  ‚ö†Ô∏è  Erro ao baixar {name}: {e}")

    # Procurar tamb√©m scripts inline
    print(f"\nüîé Procurando em scripts inline...")
    inline_scripts = soup.find_all("script", src=False)
    print(f"üìã {len(inline_scripts)} scripts inline encontrados")

    for idx, script in enumerate(inline_scripts):
        content = script.string or ""
        if "fDownload" in content and "function" in content:
            print(f"\n‚úÖ ENCONTRADO em script inline #{idx}")

            # Extrair a defini√ß√£o
            match = re.search(r"function\s+fDownload\s*\([^)]*\)\s*\{[^}]*\}", content, re.DOTALL)
            if match:
                func_code = match.group(0)
                print(f"\nüìú Defini√ß√£o da fun√ß√£o:")
                print("-" * 60)
                print(func_code)
                print("-" * 60)

            # Salvar script inline
            with open(f"inline_script_{idx}.js", "w", encoding="utf-8") as f:
                f.write(content)
            print(f"üíæ Script salvo em: inline_script_{idx}.js")

except Exception as e:
    print(f"\n‚ùå ERRO: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "="*60)
print("‚úÖ Busca conclu√≠da!")
